{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet for Person segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn-AiJJ0lCF7",
        "outputId": "50875e11-d5ae-430e-e5bc-b951a8066dcc"
      },
      "source": [
        "!git clone https://github.com/nikhilroxtomar/Unet-for-Person-Segmentation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Unet-for-Person-Segmentation'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 41 (delta 11), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IZFcuNN-ol2",
        "outputId": "de7945d9-bca3-461f-c950-936435d76dea"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-NctaNyEoOu",
        "outputId": "9bf05d87-9aa0-4404-fb71-c2a52cde74bc"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from keras.utils.vis_utils import plot_model\r\n",
        "\r\n",
        "\r\n",
        "def conv_block(input, num_filters):\r\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation(\"relu\")(x)\r\n",
        "\r\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation(\"relu\")(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "def encoder_block(input, num_filters):\r\n",
        "    x = conv_block(input, num_filters)\r\n",
        "    p = MaxPool2D((2, 2))(x)\r\n",
        "    return x, p   # X returns values before Pooling and P returns values after Pooling\r\n",
        "\r\n",
        "def decoder_block(input, skip_features, num_filters):#1024,512\r\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\r\n",
        "    x = Concatenate()([x, skip_features])\r\n",
        "    x = conv_block(x, num_filters)\r\n",
        "    return x\r\n",
        "\r\n",
        "def build_unet(input_shape):\r\n",
        "    inputs = Input(input_shape)\r\n",
        "\r\n",
        "    s1, p1 = encoder_block(inputs, 64)\r\n",
        "    s2, p2 = encoder_block(p1, 128)\r\n",
        "    s3, p3 = encoder_block(p2, 256)\r\n",
        "    s4, p4 = encoder_block(p3, 512)\r\n",
        "\r\n",
        "    b1 = conv_block(p4, 1024)\r\n",
        "\r\n",
        "    d1 = decoder_block(b1, s4, 512) # 1024 and 512\r\n",
        "    d2 = decoder_block(d1, s3, 256)\r\n",
        "    d3 = decoder_block(d2, s2, 128)\r\n",
        "    d4 = decoder_block(d3, s1, 64)\r\n",
        "\r\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\r\n",
        "\r\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\r\n",
        "    return model\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    input_shape = (512, 512, 3)\r\n",
        "    model = build_unet(input_shape)\r\n",
        "    model.summary()\r\n",
        "    plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 512, 512, 64) 1792        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 512, 512, 64) 256         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 512, 512, 64) 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 512, 512, 64) 36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 512, 512, 64) 256         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 512, 512, 64) 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 256, 256, 64) 0           activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 256, 256, 128 73856       max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 256, 256, 128 512         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 256, 256, 128 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 256, 256, 128 147584      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 256, 256, 128 512         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 256, 256, 128 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 128, 128, 128 0           activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 128, 128, 256 295168      max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 128, 128, 256 1024        conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 128, 128, 256 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 128, 128, 256 590080      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 128, 128, 256 1024        conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 128, 128, 256 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 64, 64, 256)  0           activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 64, 64, 512)  1180160     max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 64, 64, 512)  2048        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 64, 64, 512)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 64, 64, 512)  2359808     activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 64, 64, 512)  2048        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 64, 64, 512)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 32, 32, 512)  0           activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 32, 32, 1024) 4719616     max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 32, 32, 1024) 4096        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 32, 32, 1024) 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 32, 32, 1024) 9438208     activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 32, 32, 1024) 4096        conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 32, 32, 1024) 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DTran (None, 64, 64, 512)  2097664     activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 64, 64, 1024) 0           activation_61[0][0]              \n",
            "                                                                 conv2d_transpose_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 64, 64, 512)  2048        conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 64, 64, 512)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 64, 64, 512)  2359808     activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 64, 64, 512)  2048        conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 64, 64, 512)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DTran (None, 128, 128, 256 524544      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 128, 128, 512 0           activation_59[0][0]              \n",
            "                                                                 conv2d_transpose_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 128, 128, 256 1024        conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 128, 128, 256 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 128, 128, 256 590080      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 128, 128, 256 1024        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 128, 128, 256 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_14 (Conv2DTran (None, 256, 256, 128 131200      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 256, 256, 256 0           activation_57[0][0]              \n",
            "                                                                 conv2d_transpose_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 256, 256, 128 295040      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 256, 256, 128 512         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 256, 256, 128 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 256, 256, 128 147584      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 256, 256, 128 512         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 256, 256, 128 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_15 (Conv2DTran (None, 512, 512, 64) 32832       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 512, 512, 128 0           activation_55[0][0]              \n",
            "                                                                 conv2d_transpose_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 512, 512, 64) 256         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 512, 512, 64) 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 512, 512, 64) 36928       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 512, 512, 64) 256         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 512, 512, 64) 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 512, 512, 1)  65          activation_71[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 31,055,297\n",
            "Trainable params: 31,043,521\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qako2znBEqqj",
        "outputId": "4cff41ce-2618-4fe8-fde9-4df0a780193a"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "from glob import glob\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "def read_image(path):\r\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\r\n",
        "    x = cv2.resize(x, (256, 256))\r\n",
        "    x = x / 255.0\r\n",
        "    x = x.astype(np.float32)\r\n",
        "    return x\r\n",
        "\r\n",
        "def read_mask(path):\r\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\r\n",
        "    x = cv2.resize(x, (256, 256))\r\n",
        "    x = x.astype(np.float32)\r\n",
        "    x = np.expand_dims(x, axis=-1)\r\n",
        "    return x\r\n",
        "\r\n",
        "def load_dataset(dataset_path):\r\n",
        "    images = glob(os.path.join(dataset_path, \"images/*\"))\r\n",
        "    masks = glob(os.path.join(dataset_path, \"masks/*\"))\r\n",
        "\r\n",
        "    train_x, test_x = train_test_split(images, test_size=0.2, random_state=42)\r\n",
        "    train_y, test_y = train_test_split(masks, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "    return (train_x, train_y), (test_x, test_y)\r\n",
        "\r\n",
        "def preprocess(image_path, mask_path):\r\n",
        "    def f(image_path, mask_path):\r\n",
        "        image_path = image_path.decode()\r\n",
        "        mask_path = mask_path.decode()\r\n",
        "\r\n",
        "        x = read_image(image_path)\r\n",
        "        y = read_mask(mask_path)\r\n",
        "\r\n",
        "        return x, y\r\n",
        "\r\n",
        "    image, mask = tf.numpy_function(f, [image_path, mask_path], [tf.float32, tf.float32])\r\n",
        "    image.set_shape([256, 256, 3])\r\n",
        "    mask.set_shape([256, 256, 1])\r\n",
        "\r\n",
        "    return image, mask\r\n",
        "\r\n",
        "def tf_dataset(images, masks, batch=8):\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, masks))\r\n",
        "    dataset = dataset.shuffle(buffer_size=5000)\r\n",
        "    dataset = dataset.map(preprocess)\r\n",
        "    dataset = dataset.batch(batch)\r\n",
        "    dataset = dataset.prefetch(2)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    dataset_path = \"/content/drive/MyDrive/Segmentation Datasets\"\r\n",
        "    (train_x, train_y), (test_x, test_y) = load_dataset(dataset_path)\r\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\r\n",
        "    print(f\"Test: {len(test_x)} - {len(test_y)}\")\r\n",
        "\r\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=8)\r\n",
        "\r\n",
        "    # for images, masks in train_dataset:\r\n",
        "    #     print(images.shape, masks.shape)\r\n",
        "\r\n",
        "    ## 10 - 3\r\n",
        "    ## 10//3 = 3\r\n",
        "    ## 3 * 3 = 9\r\n",
        "    ## 3 + 1\r\n",
        "\r\n",
        "    # train_steps = len(train_x)//8\r\n",
        "    # if len(train_x) % 8 != 0:\r\n",
        "    #     train_steps += 1\r\n",
        "    #\r\n",
        "    # print(f\"Train Steps: {train_steps}\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 4542 - 4542\n",
            "Test: 1136 - 1136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo8guDfdlCyG",
        "outputId": "d15fd89b-19d8-4101-f1d1-26332b71d7f8"
      },
      "source": [
        "import os\r\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "# from model import build_unet\r\n",
        "# from data import load_dataset, tf_dataset\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    \"\"\" Hyperparamaters \"\"\"\r\n",
        "    dataset_path = \"/content/drive/MyDrive/Segmentation Datasets\"\r\n",
        "    input_shape = (256, 256, 3)\r\n",
        "    batch_size = 12\r\n",
        "    epochs = 100\r\n",
        "    lr = 1e-4\r\n",
        "    model_path = \"myunet.h5\"\r\n",
        "    csv_path = \"data.csv\"\r\n",
        "\r\n",
        "    \"\"\" Load the dataset \"\"\"\r\n",
        "    (train_x, train_y), (test_x, test_y) = load_dataset(dataset_path)\r\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\r\n",
        "    print(f\"Test: {len(test_x)} - {len(test_y)}\")\r\n",
        "\r\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\r\n",
        "    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\r\n",
        "\r\n",
        "    \"\"\" Model \"\"\"\r\n",
        "    model = build_unet(input_shape)\r\n",
        "    model.compile(\r\n",
        "        loss=\"binary_crossentropy\",\r\n",
        "        optimizer=tf.keras.optimizers.Adam(lr),\r\n",
        "        metrics=[\r\n",
        "            tf.keras.metrics.MeanIoU(num_classes=2),\r\n",
        "            tf.keras.metrics.Recall(),\r\n",
        "            tf.keras.metrics.Precision(),\r\n",
        "            tf.keras.metrics.Accuracy()\r\n",
        "        ]\r\n",
        "    )\r\n",
        "\r\n",
        "    # model.summary()\r\n",
        "\r\n",
        "    callbacks = [\r\n",
        "        ModelCheckpoint(model_path, monitor=\"val_loss\", verbose=1),\r\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", patience=5, factor=0.1, verbose=1),\r\n",
        "        CSVLogger(csv_path),\r\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10)\r\n",
        "    ]\r\n",
        "\r\n",
        "    train_steps = len(train_x)//batch_size\r\n",
        "    if len(train_x) % batch_size != 0:\r\n",
        "        train_steps += 1\r\n",
        "\r\n",
        "    test_steps = len(test_x)//batch_size\r\n",
        "    if len(test_x) % batch_size != 0:\r\n",
        "        test_steps += 1\r\n",
        "\r\n",
        "    model.fit(\r\n",
        "        train_dataset,\r\n",
        "        validation_data=test_dataset,\r\n",
        "        epochs=epochs,\r\n",
        "        steps_per_epoch=train_steps,\r\n",
        "        validation_steps=test_steps,\r\n",
        "        callbacks=callbacks\r\n",
        "    )\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 4542 - 4542\n",
            "Test: 1136 - 1136\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN37PI0rPJ_l"
      },
      "source": [
        "import os\r\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "from glob import glob\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    \"\"\" Load the test images \"\"\"\r\n",
        "    test_images = glob(\"images/*\")\r\n",
        "\r\n",
        "    \"\"\" Load the model \"\"\"\r\n",
        "    model = tf.keras.models.load_model(\"myunet.h5\")\r\n",
        "\r\n",
        "    for path in tqdm(test_images, total=len(test_images)):\r\n",
        "        x = cv2.imread(path, cv2.IMREAD_COLOR)\r\n",
        "        original_image = x\r\n",
        "        h, w, _ = x.shape\r\n",
        "\r\n",
        "        x = cv2.resize(x, (256, 256))\r\n",
        "        x = x/255.0\r\n",
        "        x = x.astype(np.float32)\r\n",
        "\r\n",
        "        x = np.expand_dims(x, axis=0)\r\n",
        "        pred_mask = model.predict(x)[0]\r\n",
        "\r\n",
        "        pred_mask = np.concatenate(\r\n",
        "            [\r\n",
        "                pred_mask,\r\n",
        "                pred_mask,\r\n",
        "                pred_mask\r\n",
        "            ], axis=2)\r\n",
        "        pred_mask = (pred_mask > 0.5) * 255\r\n",
        "        pred_mask = pred_mask.astype(np.float32)\r\n",
        "        pred_mask = cv2.resize(pred_mask, (w, h))\r\n",
        "\r\n",
        "        original_image = original_image.astype(np.float32)\r\n",
        "\r\n",
        "        alpha = 0.6\r\n",
        "        cv2.addWeighted(pred_mask, alpha, original_image, 1-alpha, 0, original_image)\r\n",
        "\r\n",
        "        name = path.split(\"/\")[-1]\r\n",
        "        cv2.imwrite(f\"save_images/{name}\", original_image)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}